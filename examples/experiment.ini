[main]
name="translation"
tf_manager=<tf_manager>
output="test"
batch_size=60
epochs=10
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner_greedy>]
evaluation=[("target_greedy", "target", <bleu>)]
initial_variables="lt-exp-30k/lt-ep-bl/variables.data"
logging_period=80
validation_period=100
random_seed=42
overwrite_output_dir=True

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=16
num_sessions=1
report_gpu_memory_consumption=True

[bpe_preprocess]
class=processors.bpe.BPEPreprocessor
merge_file="data/bpe_merges"

[bpe_postprocess]
class=processors.bpe.BPEPostprocessor

[bleu]
class=evaluators.bleu.BLEUEvaluator

[train_data]
class=dataset.load_dataset_from_files
s_source="data/ted-train/train.de"
s_target="data/ted-train/train.en"
preprocessors=[("source", "source_bpe", <bpe_preprocess>), ("target", "target_bpe", <bpe_preprocess>)]
lazy=True

[val_data]
class=dataset.load_dataset_from_files
s_source="data/ted-dev/dev.de"
s_target="data/ted-dev/dev.en"
preprocessors=[("source", "source_bpe", <bpe_preprocess>), ("target", "target_bpe", <bpe_preprocess>)]

[shared_vocabulary]
class=vocabulary.from_bpe
path="data/bpe_merges"

[encoder]
class=encoders.recurrent.SentenceEncoder
name="encoder"
rnn_size=1024
max_input_len=60
embedding_size=500
dropout_keep_prob=0.8
data_id="source_bpe"
vocabulary=<shared_vocabulary>

[attention]
class=attention.Attention
name="attention_sentence_encoder"
encoder=<encoder>

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<encoder>]
rnn_size=1024
embedding_size=500
attentions=[<attention>]
dropout_keep_prob=0.8
data_id="target_bpe"
max_output_len=60
vocabulary=<shared_vocabulary>
conditional_gru=True

[trainer]
class=trainers.generic_trainer.GenericTrainer
objectives=[<bandit>]
l2_weight=1.0e-08
clip_norm=1.0
optimizer=<optimizer>

[bandit]
class=trainers.bandit_trainer.expected_loss_objective
decoder=<decoder>
reward_function=<reward>
control_variate="baseline"

[reward]
class=evaluators.gleu.GLEUEvaluator
name="GLEU"

[optimizer]
class=config.utils.adam_optimizer
learning_rate=1.0e-5

[runner_greedy]
class=runners.runner.GreedyRunner
output_series="target_greedy"
decoder=<decoder>
postprocess=<bpe_postprocess>

